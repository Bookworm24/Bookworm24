import tensorflow as tf
import os
import numpy as np
from matplotlib import pyplot as plt
from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense
from tensorflow.keras import Model

np.set_printoptions(threshold=np.inf)

cifar10 = tf.keras.datasets.cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

"""
å·ç§¯å±‚åœ¨ç¥ç»ç½‘ç»œæ¨¡å‹ä¸­çš„é‡è¦ä½œç”¨:

1. æå–ç©ºé—´ç‰¹å¾ã€‚å·ç§¯å±‚é€šè¿‡æ»‘åŠ¨è¿‡æ»¤å™¨è¿ç®—,å¯ä»¥æœ‰æ•ˆæå–è¾“å…¥ä¿¡å·åœ¨ç©ºé—´ç»´åº¦ä¸Šçš„æœ‰ç”¨ç‰¹å¾,å¦‚è¾¹ç¼˜ã€é¢œè‰²å˜åŒ–ç­‰ã€‚è¿™å¯¹å›¾åƒã€è§†é¢‘ç­‰ç»“æ„åŒ–æ•°æ®éå¸¸æœ‰æ•ˆã€‚

2. å¼ºå¤§çš„è¡¨è¾¾èƒ½åŠ›ã€‚å¤šå±‚æ¬¡çš„å·ç§¯ç½‘ç»œå¯ä»¥å­¦ä¹ å‡ºé«˜çº§æŠ½è±¡ç‰¹å¾,æœ‰æ•ˆå®ç°å¤æ‚è®¡ç®—æœºè§†è§‰ç­‰ä»»åŠ¡ã€‚

3. å‚æ•°å…±äº«ã€‚å·ç§¯å±‚é€šè¿‡å‚æ•°å…±äº«,å¤§å¤§å‡å°‘æ¨¡å‹å‚æ•°æ•°é‡,ç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜ã€‚

4. æ¨¡å‹å¯ç§»æ¤æ€§å¥½ã€‚å·ç§¯ç½‘ç»œå­¦ä¹ å‡ºçš„ç‰¹å¾æå–é€šå¸¸å…·æœ‰å¾ˆå¼ºçš„æ¨¡æ‹Ÿæ€§,èƒ½åº”ç”¨äºä¸åŒæ•°æ®é›†å’Œä»»åŠ¡ã€‚

5. å¯¹ç©ºé—´å˜åŒ–ä¸æ•æ„Ÿã€‚å·ç§¯æ“ä½œå¯¹è¾“å…¥ä¿¡å·ä½ç½®ä¿¡æ¯ä¸é‚£ä¹ˆæ•æ„Ÿ,å¯ä»¥æå–å‡ºç©ºé—´ä¸å˜çš„ç‰¹å¾ã€‚

å…·ä½“æ¥è¯´,å·ç§¯å±‚åœ¨ä»¥ä¸‹ä»»åŠ¡ä¸­æ•ˆæœæ˜¾è‘—:

- å›¾åƒåˆ†ç±»:å¦‚MNISTã€CIFARã€ImageNetç­‰  
- ç›®æ ‡æ£€æµ‹:å›¾åƒä¸­å…·ä½“åŒºåŸŸå¯¹è±¡æ£€æµ‹
- å›¾åƒåˆ†å‰²:ä¸åŒéƒ¨åˆ†å›¾åƒçš„åˆ†å‰²
- å›¾åƒé£æ ¼è¿ç§»:æå–å†…å®¹ç‰¹å¾ä¸é£æ ¼ç‰¹å¾
- è‡ªç„¶è¯­è¨€å¤„ç†:åµŒå…¥å±‚å­¦ä¹ è¯æ±‡ç‰¹å¾
- ç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†æ:CTã€MRIçš„æ•°æ®åˆ†ç±»è¯Šæ–­

æ€»ä¹‹,é€šè¿‡æœ‰æ•ˆæå–è¾“å…¥ç©ºé—´ç»“æ„ç‰¹å¾,å·ç§¯å±‚å¤§å¤§å¢å¼ºäº†ç¥ç»ç½‘ç»œå­¦ä¹ å¤æ‚æ¨¡å¼çš„èƒ½åŠ›,åœ¨å„ç±»è®¡ç®—æœºè§†è§‰å’Œåºåˆ—ä»»åŠ¡ä¸­éƒ½å‘æŒ¥é‡è¦ä½œç”¨ã€‚
"""
"""
tf.keras.layers.Conv2D æ˜¯ Keras ä¸­ å®šä¹‰ 2D å·ç§¯å±‚çš„ç±»ã€‚

ä¸»è¦å±æ€§å’Œæ–¹æ³•:

- filters:æ•´æ•°,è¾“å‡ºç©ºé—´çš„ç»´åº¦(å³å·ç§¯æ ¸æ•°)ã€‚

- kernel_size:æ•´æ•°æˆ–å…ƒç»„é•¿åº¦ä¸º 2 çš„æ•´æ•°åˆ—è¡¨,æŒ‡å®šå·ç§¯çª—å£çš„å®½åº¦å’Œé«˜åº¦ã€‚ 

- strides:æ•´æ•°æˆ–å…ƒç»„é•¿åº¦ä¸º 2 çš„æ•´æ•°åˆ—è¡¨,æŒ‡å®šæ»‘åŠ¨æ­¥é•¿çš„å®½åº¦å’Œé«˜åº¦ã€‚

- padding:â€˜validâ€™ æˆ– â€˜sameâ€™,æŒ‡å®šè¡¥è¾¹æ–¹å¼ã€‚

- data_format:â€˜channels_firstâ€™ æˆ– â€˜channels_lastâ€™ã€‚

- dilation_rate:æ•´æ•°æˆ–å…ƒç»„é•¿åº¦ä¸º 2 çš„æ•´æ•°åˆ—è¡¨,æŒ‡å®šè†¨èƒ€ç‡ã€‚

- activation:æ¿€æ´»å‡½æ•°,é»˜è®¤ä¸º Noneã€‚

- use_bias:å¸ƒå°”å€¼,æ˜¯å¦æ·»åŠ åç½®å‘é‡ã€‚

- kernel_initializer:æƒé‡åˆå§‹åŒ–æ–¹æ³•ã€‚

- bias_initializer:åç½®åˆå§‹åŒ–æ–¹æ³•ã€‚

- kernel_regularizer:æ­£åˆ™åŒ–æƒé‡çŸ©é˜µçš„æ–¹æ³•ã€‚

- bias_regularizer:æ­£åˆ™åŒ–åç½®å‘é‡çš„æ–¹æ³•ã€‚

- activity_regularizer:æ­£åˆ™åŒ–å·ç§¯å±‚è¾“å‡ºçš„æ–¹æ³•ã€‚

- kernel_constraint:æƒé‡å€¼çš„çº¦æŸã€‚

- bias_constraint:åç½®å€¼çš„çº¦æŸã€‚

ä¸»è¦æ–¹æ³•:

- call(inputs):æ‰§è¡Œå‰å‘ä¼ æ’­,è¿”å›tensor.

ç”¨æ³•:

```python
x = Conv2D(filters, kernel_size, strides=(1, 1), 
           padding='valid', activation='relu')(inputs)
```

å®ƒå¯ä»¥å¾ˆçµæ´»åœ°å®šä¹‰å¸¸è§çš„å·ç§¯å±‚ç»“æ„,åœ¨ CNN ä¸­å¹¿æ³›åº”ç”¨ã€‚

æ‰¹æ ‡å‡†åŒ–ï¼ˆBatch Normalizationï¼Œ BNï¼‰
ğ‘¯ğ‘¯ğ’Šğ’Š
â€²ğ’Œğ’Œ =
ğ‘¯ğ‘¯ğ’Šğ’Š
ğ’Œğ’Œ âˆ’ ğğbatch
ğ’Œğ’Œ
ğˆğˆbatch
ğ’Œğ’Œ
ğ‘¯ğ‘¯ğ’Šğ’Š
ğ’Œğ’Œ
ï¼š æ‰¹æ ‡å‡†åŒ–å‰ï¼Œç¬¬kä¸ªå·ç§¯æ ¸ï¼Œè¾“å‡ºç‰¹å¾å›¾ä¸­ç¬¬ i ä¸ªåƒç´ ç‚¹
ğğbatch
ğ’Œğ’Œ
ï¼šæ‰¹æ ‡å‡†åŒ–å‰ï¼Œç¬¬kä¸ªå·ç§¯æ ¸ï¼Œbatchå¼ è¾“å‡ºç‰¹å¾å›¾ä¸­æ‰€æœ‰åƒç´ ç‚¹å¹³å‡å€¼
ğˆğˆbatch
ğ’Œğ’Œ
ï¼šæ‰¹æ ‡å‡†åŒ–å‰ï¼Œç¬¬kä¸ªå·ç§¯æ ¸ï¼Œbatchå¼ è¾“å‡ºç‰¹å¾å›¾ä¸­æ‰€æœ‰åƒç´ ç‚¹æ ‡å‡†å·®
ğğbatch
ğ’Œğ’Œ = ğŸğŸ
ğ’ğ’ï¿½
i =ğŸğŸ
ğ’ğ’
ğ‘¯ğ‘¯ğ’Šğ’Š
ğ’Œğ’Œ ğˆğˆbatch
ğ’Œğ’Œ = ğœ¹ğœ¹ +
ğŸğŸ
ğ’ğ’ï¿½
i =ğŸğŸ
ğ’ğ’
(ğ‘¯ğ‘¯ğ’Šğ’Š
ğ’Œğ’Œâˆ’ğğbatch
ğ’Œğ’Œ )ğŸğŸ
æ‰¹æ ‡å‡†åŒ–åï¼Œç¬¬ kä¸ªå·ç§¯æ ¸çš„è¾“å‡ºç‰¹å¾å›¾ï¼ˆfeature mapï¼‰ä¸­ç¬¬ i ä¸ªåƒç´ ç‚¹
æ ‡å‡†åŒ–ï¼šä½¿æ•°æ®ç¬¦åˆ0å‡å€¼ï¼Œ1ä¸ºæ ‡å‡†å·®çš„åˆ†å¸ƒã€‚
æ‰¹æ ‡å‡†åŒ–ï¼šå¯¹ä¸€å°æ‰¹æ•°æ®ï¼ˆbatchï¼‰ï¼Œåšæ ‡å‡†åŒ–å¤„ç† ã€‚

æ± åŒ–ç”¨äºå‡å°‘ç‰¹å¾æ•°æ®é‡ã€‚
æœ€å¤§å€¼æ± åŒ–å¯æå–å›¾ç‰‡çº¹ç†ï¼Œå‡å€¼æ± åŒ–å¯ä¿ç•™èƒŒæ™¯ç‰¹å¾ã€‚
Baselineç»§æ‰¿äºtf.keras.Model,å®ç°äº†__init__å’Œcallæ–¹æ³•,å®šä¹‰äº†ä¸€ä¸ªKeraså‡½æ•°æ¨¡å‹ã€‚

__init__ä¸­ä½¿ç”¨äº†Sequentialçš„é£æ ¼,å®šä¹‰äº†ä¸€ä¸ªæ ‡å‡†çš„å·ç§¯ç¥ç»ç½‘ç»œå‰å‘ç»“æ„,åŒ…å«å·ç§¯å±‚ã€BNå±‚ã€æ± åŒ–å±‚ã€ Dropoutå±‚ç­‰ã€‚

callæ–¹æ³•å®šä¹‰äº†å‰å‘è®¡ç®—è¿‡ç¨‹,æŒ‰é¡ºåºå°†è¾“å…¥xä¼ é€’ç»™æ¯ä¸€å±‚,å¾—åˆ°æœ€ç»ˆè¾“å‡ºyã€‚

æ¯ä¸€å±‚éƒ½ä½¿ç”¨å¯¹åº”çš„Keraså±‚å®šä¹‰,å¦‚Conv2Dã€BatchNormalizationã€MaxPool2Dç­‰ã€‚

åœ¨æœ€åflattenå±‚åæ¥ä¸¤ä¸ªDenseå±‚ç»„æˆå…¨è¿æ¥éƒ¨åˆ†,è¿›è¡Œåˆ†ç±»ã€‚
"""
class Baseline(Model):
    def __init__(self):
        super(Baseline, self).__init__()
        self.c1 = Conv2D(filters=6, kernel_size=(5, 5), padding='same')  # å·ç§¯å±‚
        self.b1 = BatchNormalization()  # BNå±‚
        self.a1 = Activation('relu')  # æ¿€æ´»å±‚
        self.p1 = MaxPool2D(pool_size=(2, 2), strides=2, padding='same')  # æ± åŒ–å±‚
        self.d1 = Dropout(0.2)  # dropoutå±‚

        self.flatten = Flatten()
        self.f1 = Dense(128, activation='relu')
        self.d2 = Dropout(0.2)
        self.f2 = Dense(10, activation='softmax')

    def call(self, x):
        x = self.c1(x)
        x = self.b1(x)
        x = self.a1(x)
        x = self.p1(x)
        x = self.d1(x)

        x = self.flatten(x)
        x = self.f1(x)
        x = self.d2(x)
        y = self.f2(x)
        return y
"""
model = tf.keras.models.Sequential([
Conv2D(filters=6, kernel_size=(5, 5), padding='same'), # å·ç§¯å±‚
BatchNormalization(), # BNå±‚
Activation('relu'), # æ¿€æ´»å±‚
MaxPool2D(pool_size=(2, 2), strides=2, padding='same'), # æ± åŒ–å±‚
Dropout(0.2), # dropoutå±‚
"""

model = Baseline()

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
              metrics=['sparse_categorical_accuracy'])

checkpoint_save_path = "./checkpoint/Baseline.ckpt"
if os.path.exists(checkpoint_save_path + '.index'):
    print('-------------load the model-----------------')
    model.load_weights(checkpoint_save_path)

cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,
                                                 save_weights_only=True,
                                                 save_best_only=True)

history = model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), validation_freq=1,
                    callbacks=[cp_callback])
model.summary()

# print(model.trainable_variables)
file = open('./weights.txt', 'w')
for v in model.trainable_variables:
    file.write(str(v.name) + '\n')
    file.write(str(v.shape) + '\n')
    file.write(str(v.numpy()) + '\n')
file.close()

###############################################    show   ###############################################

# æ˜¾ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„accå’Œlossæ›²çº¿
acc = history.history['sparse_categorical_accuracy']
val_acc = history.history['val_sparse_categorical_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.subplot(1, 2, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()
